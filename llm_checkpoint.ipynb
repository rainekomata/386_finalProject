{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://www.piwheels.org/simple\n",
      "Collecting ollama\n",
      "  Downloading ollama-0.4.8-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpx<0.29,>=0.27 (from ollama)\n",
      "  Downloading https://www.piwheels.org/simple/httpx/httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Collecting pydantic<3.0.0,>=2.9.0 (from ollama)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting anyio (from httpx<0.29,>=0.27->ollama)\n",
      "  Downloading https://www.piwheels.org/simple/anyio/anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Collecting certifi (from httpx<0.29,>=0.27->ollama)\n",
      "  Downloading https://www.piwheels.org/simple/certifi/certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.29,>=0.27->ollama)\n",
      "  Downloading httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<0.29,>=0.27->ollama)\n",
      "  Downloading https://www.piwheels.org/simple/idna/idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.29,>=0.27->ollama)\n",
      "  Downloading https://www.piwheels.org/simple/h11/h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading https://www.piwheels.org/simple/annotated-types/annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in ./.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.2)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.9.0->ollama)\n",
      "  Downloading https://www.piwheels.org/simple/typing-inspection/typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<0.29,>=0.27->ollama)\n",
      "  Downloading https://www.piwheels.org/simple/sniffio/sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading ollama-0.4.8-py3-none-any.whl (13 kB)\n",
      "Downloading httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing-inspection, sniffio, pydantic-core, idna, h11, certifi, annotated-types, pydantic, httpcore, anyio, httpx, ollama\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 certifi-2025.1.31 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 idna-3.10 ollama-0.4.8 pydantic-2.11.3 pydantic-core-2.33.1 sniffio-1.3.1 typing-inspection-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This script evaluates an LLM prompt for processing text so that it can be used for the wttr.in API\"\"\"\n",
    "\n",
    "from ollama import Client\n",
    "\n",
    "LLM_MODEL: str = \"gemma3:27b\"  \n",
    "client: Client = Client(\n",
    "    host=\"http://ai.dfec.xyz:11434\" \n",
    ")\n",
    "\n",
    "def llm_parse_for_wttr(raw_text: str) -> str:\n",
    "    response = client.chat(model=LLM_MODEL, messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': raw_text\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": '''You are processing raw text for programmatic input. I'm going to explain the wttr.in format to you. Your job is to extract and return **ONLY**\n",
    "            the spot the user is asking about. \n",
    "            ## Instructions\n",
    "            -for any location with a space in the name, use + instead of a space\n",
    "            -use 3-letter airport codes in order to get the weather information at a certain airport\n",
    "            -for any geographical location other than a town or city (it could be an attraction in the city, moutain name, or special location), \n",
    "            add the character ~ before the name to look up that special location name before the weather\n",
    "            -if the word inclues a mountain, state it as \"mt\"\n",
    "            ## Example: \n",
    "            -input: Rio Rancho, expected: Rio+Rancho\n",
    "            -input: Empire State, expected: ~Empire+State\n",
    "            -input: Honolulu airport, expected: HNL'''\n",
    "        },\n",
    "    ])\n",
    "    return response.message.content #insert prompt - this functiuon talks to the LLM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cases\n",
    "# Test cases\n",
    "test_cases = [  # TODO: Replace these test cases with ones for wttr.in\n",
    "    {\"input\": \"What's the weather in Rio Rancho?\", \"expected\": \"Rio+Rancho\"},\n",
    "    {\"input\": \"What is the weather at the Empire State.\", \"expected\": \"~Empire+State\"},\n",
    "    {\"input\": \"What's the weather at the Honolulu airport\", \"expected\": \"HNL\"},\n",
    "    {\"input\": \"What's the weather at Mount Fuji\", \"expected\": \"mt+Fuji\"},\n",
    "    {\"input\": \"What's the weather at the Oakland International airport\", \"expected\": \"OAK\"},\n",
    "    {\"input\": \"What's the weather in Glenwood Springs\", \"expected\": \"Glenwood+Springs\"},\n",
    "    {\"input\": \"What's the weather at Disneyland\", \"expected\": \"~Disneyland\"},\n",
    "    {\"input\": \"What's the weather in Mililani\", \"expected\": \"Mililani\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My code\n",
    "\n",
    "def run_tests(test_cases: list[dict[str, str]]):\n",
    "    \"\"\"run_tests iterates through a list of dictionaries,\n",
    "    runs them against an LLM, and reports the results.\"\"\"\n",
    "    num_passed = 0\n",
    "\n",
    "    for i, test in enumerate(test_cases, 1):\n",
    "        raw_input = test[\"input\"]\n",
    "        expected_output = test[\"expected\"]\n",
    "\n",
    "        print(f\"\\nTest {i}: {raw_input}\")\n",
    "        try:\n",
    "            result = llm_parse_for_wttr(raw_input).strip()\n",
    "            expected = expected_output.strip()\n",
    "\n",
    "            print(\"LLM Output  :\", result)\n",
    "            print(\"Expected    :\", expected)\n",
    "\n",
    "            if result == expected:\n",
    "                print(\"‚úÖ PASS\")\n",
    "                num_passed += 1\n",
    "            else:\n",
    "                print(\"‚ùå FAIL\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"üí• ERROR:\", e)\n",
    "\n",
    "    print(f\"\\nSummary: {num_passed} / {len(test)} tests passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test 1: What's the weather in Rio Rancho?\n",
      "LLM Output  : Rio+Rancho\n",
      "Expected    : Rio+Rancho\n",
      "‚úÖ PASS\n",
      "\n",
      "Test 2: What is the weather at the Empire State.\n",
      "LLM Output  : ~Empire+State\n",
      "Expected    : ~Empire+State\n",
      "‚úÖ PASS\n",
      "\n",
      "Test 3: What's the weather at the Honolulu airport\n",
      "LLM Output  : HNL\n",
      "Expected    : HNL\n",
      "‚úÖ PASS\n",
      "\n",
      "Test 4: What's the weather at Mount Fuji\n",
      "LLM Output  : mt+Fuji\n",
      "Expected    : mt+Fuji\n",
      "‚úÖ PASS\n",
      "\n",
      "Test 5: What's the weather at the Oakland International airport\n",
      "LLM Output  : OAK\n",
      "Expected    : OAK\n",
      "‚úÖ PASS\n",
      "\n",
      "Test 6: What's the weather in Glenwood Springs\n",
      "LLM Output  : Glenwood+Springs\n",
      "Expected    : Glenwood+Springs\n",
      "‚úÖ PASS\n",
      "\n",
      "Test 7: What's the weather at Disneyland\n",
      "LLM Output  : ~Disneyland\n",
      "Expected    : ~Disneyland\n",
      "‚úÖ PASS\n",
      "\n",
      "Test 8: What's the weather in Mililani\n",
      "LLM Output  : Mililani\n",
      "Expected    : Mililani\n",
      "‚úÖ PASS\n",
      "\n",
      "Summary: 8 / 2 tests passed.\n"
     ]
    }
   ],
   "source": [
    "# Run test cases\n",
    "\n",
    "run_tests(test_cases=test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Documentation Statement: used wttr.in github to help me write the instructions.\n",
    "# Capt Yarbrough also assisted and guided me through how to form proper instructions and test cases for the LLM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
